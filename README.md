# M$^{2}$HGR: Multi-modal Multi-feature Hand Gesture Recognition Based on sEMG and Vision Fusion for Robotic Teleoperation

This is the official implementation of "Multi-modal Multi-feature Hand Gesture Recognition Based on sEMG and Vision Fusion for Robotic Teleoperation" on PyTorch platform.


## The released codes include:
    results/:                           the folder for model weights and visualization.
    dataset/:                           the folder for orignal data.
    dataloader/:                        the folder for data loader.
    common/:                            the folder for basic functions.
    models/:                            the folder for networks (different versions).
    train_xx.py:                        the python code for networks' training.

## Environment
Make sure you have the following dependencies installed:
* PyTorch >= 1.3.0
* NumPy
* Matplotlib
* sklearn
* pickle
* tqdm


## Datasets

- We employed our proprietary sEMG-visual dataset to train our network architecture. 
- We anticipate making this dataset publicly available through an open-source release in the near future.


## Training 
Updating...


## Evaluation
Updating...


## Inference
Updating...


## Citation

If you find this repo useful, please consider citing our paper:...

## Acknowledgement
Our code refers to the following repositories. We thank the authors for releasing the codes.

- [DD-Net](https://github.com/BlurryLight/DD-Net-Pytorch) 
- [pyomyo](https://github.com/PerlinWarp/pyomyo)
